{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.optimize\n",
    "from numba import jit\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dengxiangtian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "users=pd.read_csv(\"users.dat\",sep=\"::\",header=None,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dengxiangtian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "movies=pd.read_csv(\"movies.dat\",sep=\"::\",header=None,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dengxiangtian/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "ratings=pd.read_csv(\"ratings.dat\",sep=\"::\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0     1  2          3\n",
      "0  1  1193  5  978300760\n",
      "1  1   661  3  978302109\n",
      "2  1   914  3  978301968\n",
      "3  1  3408  4  978300275\n",
      "4  1  2355  5  978824291\n",
      "   1   2   3      4\n",
      "0                  \n",
      "1  F   1  10  48067\n",
      "2  M  56  16  70072\n",
      "3  M  25  15  55117\n",
      "4  M  45   7  02460\n",
      "5  M  25  20  55455\n",
      "                                    1                             2\n",
      "0                                                                  \n",
      "1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "5  Father of the Bride Part II (1995)                        Comedy\n"
     ]
    }
   ],
   "source": [
    "print(ratings.head())\n",
    "print(users.head())\n",
    "print(movies.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=ratings[[0,1]]\n",
    "Y=ratings[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_tv,y_train,y_tv=train_test_split(X,Y,test_size=0.2,random_state=888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation,x_test,y_validation,y_test=train_test_split(x_tv,y_tv,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600334"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=max(x_train[0])\n",
    "x_train.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Brute-force\" Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class recommendation_model:\n",
    "    def __init__(self , x_train , y_train , K=5, r_lambda=0):\n",
    "        #index = user/movie_id - 1 \n",
    "        self.b_u=np.random.normal(0,1e-4,max(x_train[0]))#user bias\n",
    "        self.b_i=np.random.normal(0,1e-4,max(x_train[1]))#item bias\n",
    "        self.p_u=np.random.normal(0,1/max(1,np.sqrt(K)),[max(x_train[0]),K])# user taste\n",
    "        self.p_i=np.random.normal(0,1/max(1,np.sqrt(K)),[max(x_train[1]),K])# item style\n",
    "        self.x_train=x_train.values\n",
    "        self.y_train=y_train.values\n",
    "        self.mu=y_train.mean() # average\n",
    "        self.r_lambda=r_lambda #regulation term\n",
    "    \n",
    "    @jit(parallel=True,fastmath = True)\n",
    "    def predict(self,X):\n",
    "        x_=np.array(X)\n",
    "        y_=self.mu+self.b_u[x_[:,0]-1]+self.b_i[x_[:,1]-1]+np.sum((self.p_u[x_[:,0]-1]*self.p_i[x_[:,1]-1]),axis=1)\n",
    "        return y_\n",
    "    \n",
    "    @jit(parallel=True,fastmath = True)\n",
    "    def loss(self,X,Y):\n",
    "        x_=np.array(X)\n",
    "        y_=self.mu+self.b_u[x_[:,0]-1]+self.b_i[x_[:,1]-1]+np.sum((self.p_u[x_[:,0]-1]*self.p_i[x_[:,1]-1]),axis=1)\n",
    "        e2=(Y-y_)**2\n",
    "        return e2.mean()\n",
    "    \n",
    "    @jit(parallel=True,fastmath = True)\n",
    "    def reg_loss(self,X,Y):\n",
    "        x_=np.array(X)\n",
    "        y_=self.mu+self.b_u[x_[:,0]-1]+self.b_i[x_[:,1]-1]+np.sum((self.p_u[x_[:,0]-1]*self.p_i[x_[:,1]-1]),axis=1)\n",
    "        e2=(Y-y_)**2+0.5*self.r_lambda*np.sum((self.p_u[x_[:,0]-1]**2+self.p_i[x_[:,1]-1]**2),axis=1)\n",
    "        #print(self.r_lambda*((self.p_u**2).sum()+(self.p_i**2).sum()))\n",
    "        return e2.mean()\n",
    "    \n",
    "    @jit(parallel=True,fastmath = True,nogil=True)\n",
    "    def fit(self,batch_size=100,learning_rate=0.1,epochs=20,n_show=1):\n",
    "        for i in range(epochs):\n",
    "            d_b_u=np.zeros_like(self.b_u)\n",
    "            d_b_i=np.zeros_like(self.b_i)\n",
    "            d_p_u=np.zeros_like(self.p_u)\n",
    "            d_p_i=np.zeros_like(self.p_i)\n",
    "            samples=np.random.choice(len(x_train),batch_size,replace=False)\n",
    "            x_=self.x_train[samples]\n",
    "            y_=self.y_train[samples]\n",
    "            delta_y=y_-self.predict(x_)\n",
    "            N=len(x_train)\n",
    "           \n",
    "            for j in range(batch_size):\n",
    "                d_b_u[x_[j,0]-1]+=-delta_y[j]\n",
    "                d_b_i[x_[j,1]-1]+=-delta_y[j]\n",
    "                d_p_u[x_[j,0]-1]+=-self.p_i[x_[j,1]-1]*delta_y[j]+self.r_lambda*self.p_u[x_[j,0]-1]\n",
    "                d_p_i[x_[j,1]-1]+=-self.p_u[x_[j,0]-1]*delta_y[j]+self.r_lambda*self.p_i[x_[j,1]-1]\n",
    "            self.b_u-=learning_rate*d_b_u\n",
    "            self.b_i-=learning_rate*d_b_i\n",
    "            self.p_u-=learning_rate*d_p_u\n",
    "            self.p_i-=learning_rate*d_p_i\n",
    "            if (i+1)%n_show==0:\n",
    "                print(\"batch_size:\",batch_size,\"epochs:\",(i+1),\"reg_loss:\",self.reg_loss(self.x_train,self.y_train),\"loss:\",self.loss(self.x_train,self.y_train))\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model1=recommendation_model(x_train,y_train,10,r_lambda=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection, training and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 100 epochs: 100 reg_loss: 1.1471365802518025 loss: 1.0990765834742213\n",
      "batch_size: 100 epochs: 200 reg_loss: 1.0826498358828385 loss: 1.036901913681903\n",
      "batch_size: 100 epochs: 300 reg_loss: 1.0465873894866424 loss: 1.0025962805484587\n",
      "batch_size: 100 epochs: 400 reg_loss: 1.0212923443119553 loss: 0.9789091521870878\n",
      "batch_size: 100 epochs: 500 reg_loss: 1.0071867816270694 loss: 0.9660486284000551\n",
      "batch_size: 100 epochs: 600 reg_loss: 0.9905795663832708 loss: 0.9506052995377677\n",
      "batch_size: 100 epochs: 700 reg_loss: 0.9814125000812866 loss: 0.9422258477128274\n",
      "batch_size: 100 epochs: 800 reg_loss: 0.9802510684870942 loss: 0.9418179513910383\n",
      "batch_size: 100 epochs: 900 reg_loss: 0.9682420001638419 loss: 0.9304643790269749\n",
      "batch_size: 100 epochs: 1000 reg_loss: 0.9605956984276111 loss: 0.9235788743609211\n",
      "batch_size: 100 epochs: 1100 reg_loss: 0.9536465138146147 loss: 0.9172437242703015\n",
      "batch_size: 100 epochs: 1200 reg_loss: 0.9548043322154652 loss: 0.9188369399200647\n",
      "batch_size: 100 epochs: 1300 reg_loss: 0.9451581706710029 loss: 0.9097697574324024\n",
      "batch_size: 100 epochs: 1400 reg_loss: 0.9390586203514998 loss: 0.9042351202228712\n",
      "batch_size: 100 epochs: 1500 reg_loss: 0.9389871691780105 loss: 0.904631913581791\n",
      "batch_size: 100 epochs: 1600 reg_loss: 0.9333190351504391 loss: 0.8991800350572643\n",
      "batch_size: 100 epochs: 1700 reg_loss: 0.9301313613118319 loss: 0.8963809489679395\n",
      "batch_size: 100 epochs: 1800 reg_loss: 0.9292489262713511 loss: 0.8957164494373888\n",
      "batch_size: 100 epochs: 1900 reg_loss: 0.9271615827532694 loss: 0.8937687496758719\n",
      "batch_size: 100 epochs: 2000 reg_loss: 0.9220111451514573 loss: 0.8887794630987835\n",
      "batch_size: 100 epochs: 2100 reg_loss: 0.9178400014676548 loss: 0.8846814816185449\n",
      "batch_size: 100 epochs: 2200 reg_loss: 0.9193262972156984 loss: 0.8863726621803731\n",
      "batch_size: 100 epochs: 2300 reg_loss: 0.9262909690049229 loss: 0.8933724974925197\n",
      "batch_size: 100 epochs: 2400 reg_loss: 0.9209525727024712 loss: 0.8880507825133788\n",
      "batch_size: 100 epochs: 2500 reg_loss: 0.9172378590443864 loss: 0.8845134390297306\n",
      "batch_size: 100 epochs: 2600 reg_loss: 0.9130749931113354 loss: 0.8804257631571787\n",
      "batch_size: 100 epochs: 2700 reg_loss: 0.9147554924102652 loss: 0.8821024631605638\n",
      "batch_size: 100 epochs: 2800 reg_loss: 0.9085779658409292 loss: 0.8758720117188805\n",
      "batch_size: 100 epochs: 2900 reg_loss: 0.9067003352449674 loss: 0.8739809274141798\n",
      "batch_size: 100 epochs: 3000 reg_loss: 0.9080655086138293 loss: 0.8751890225738564\n",
      "batch_size: 100 epochs: 3100 reg_loss: 0.9106868226211979 loss: 0.8777723660993397\n",
      "batch_size: 100 epochs: 3200 reg_loss: 0.9043400785554322 loss: 0.8714117438795852\n",
      "batch_size: 100 epochs: 3300 reg_loss: 0.9060378827638377 loss: 0.8730343517809612\n",
      "batch_size: 100 epochs: 3400 reg_loss: 0.9054302916526321 loss: 0.8724301456554189\n",
      "batch_size: 100 epochs: 3500 reg_loss: 0.9006181991569445 loss: 0.8676502385233168\n",
      "batch_size: 100 epochs: 3600 reg_loss: 0.9012552189037647 loss: 0.8682257239509074\n",
      "batch_size: 100 epochs: 3700 reg_loss: 0.8983350579906685 loss: 0.865186202522166\n",
      "batch_size: 100 epochs: 3800 reg_loss: 0.9007139632979712 loss: 0.8674057241872083\n",
      "batch_size: 100 epochs: 3900 reg_loss: 0.9012758506577443 loss: 0.8678059425918487\n",
      "batch_size: 100 epochs: 4000 reg_loss: 0.8928711569927053 loss: 0.859386036260218\n",
      "batch_size: 100 epochs: 4100 reg_loss: 0.8926215370174606 loss: 0.8590379064179802\n",
      "batch_size: 100 epochs: 4200 reg_loss: 0.8902998897761106 loss: 0.8566055131495546\n",
      "batch_size: 100 epochs: 4300 reg_loss: 0.8895212298514185 loss: 0.8557679235315038\n",
      "batch_size: 100 epochs: 4400 reg_loss: 0.8916725521782121 loss: 0.8576315993347221\n",
      "batch_size: 100 epochs: 4500 reg_loss: 0.8902547733286897 loss: 0.8558524884538871\n",
      "batch_size: 100 epochs: 4600 reg_loss: 0.8865265231950821 loss: 0.8520799850844993\n",
      "batch_size: 100 epochs: 4700 reg_loss: 0.8863097163849663 loss: 0.8515652851422708\n",
      "batch_size: 100 epochs: 4800 reg_loss: 0.8826821861664829 loss: 0.8478451467167494\n",
      "batch_size: 100 epochs: 4900 reg_loss: 0.8824203345510565 loss: 0.8472001348408315\n",
      "batch_size: 100 epochs: 5000 reg_loss: 0.8819175005678558 loss: 0.8464772417331683\n",
      "CPU times: user 2min 57s, sys: 9.05 s, total: 3min 6s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "model3=recommendation_model(x_train,y_train,20,r_lambda=0.05)\n",
    "\n",
    "%time model3.fit(batch_size=100,learning_rate=0.1 ,epochs=5000,n_show=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7562660254117667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 1000 reg_loss: 0.7099770991523215 loss: 0.6586620173296177\n",
      "epochs: 2000 reg_loss: 0.7099516428001302 loss: 0.658626928360047\n",
      "epochs: 3000 reg_loss: 0.7099357887154836 loss: 0.6586082319367245\n",
      "epochs: 4000 reg_loss: 0.7099206295717254 loss: 0.6585873181061028\n",
      "epochs: 5000 reg_loss: 0.709896095681892 loss: 0.6585570897415286\n",
      "epochs: 6000 reg_loss: 0.7098667049274535 loss: 0.6585176102379706\n",
      "epochs: 7000 reg_loss: 0.7098123820839995 loss: 0.6584394299266967\n",
      "epochs: 8000 reg_loss: 0.7098078936836509 loss: 0.6584244604878694\n",
      "epochs: 9000 reg_loss: 0.7097991361436257 loss: 0.6584195902536865\n",
      "epochs: 10000 reg_loss: 0.7097744151890429 loss: 0.6583740469146875\n",
      "epochs: 11000 reg_loss: 0.7097459791431481 loss: 0.6583256962366428\n",
      "epochs: 12000 reg_loss: 0.7097415420802768 loss: 0.6583099149724168\n",
      "epochs: 13000 reg_loss: 0.709732168239454 loss: 0.658291960581764\n",
      "epochs: 14000 reg_loss: 0.7097073275477422 loss: 0.6582608845907753\n",
      "epochs: 15000 reg_loss: 0.7096856507020128 loss: 0.6582238241435946\n",
      "epochs: 16000 reg_loss: 0.709661355844473 loss: 0.6581802083886517\n",
      "epochs: 17000 reg_loss: 0.7096286528581066 loss: 0.6581320332625197\n",
      "epochs: 18000 reg_loss: 0.7096007214083601 loss: 0.6580832819278495\n",
      "epochs: 19000 reg_loss: 0.7095809183559486 loss: 0.6580453361783921\n",
      "epochs: 20000 reg_loss: 0.7095797711964539 loss: 0.6580299361550797\n",
      "epochs: 21000 reg_loss: 0.709571709039231 loss: 0.6580204250864264\n",
      "epochs: 22000 reg_loss: 0.7095391738172733 loss: 0.6579736844860178\n",
      "epochs: 23000 reg_loss: 0.7095229790192462 loss: 0.6579284819949724\n",
      "epochs: 24000 reg_loss: 0.7094815841147034 loss: 0.6578599519413457\n",
      "epochs: 25000 reg_loss: 0.7094833919109582 loss: 0.6578690330536036\n",
      "epochs: 26000 reg_loss: 0.7094743313709702 loss: 0.6578623591191274\n",
      "epochs: 27000 reg_loss: 0.7094718104715554 loss: 0.6578517655893303\n",
      "epochs: 28000 reg_loss: 0.7094581307697055 loss: 0.6578386340934267\n",
      "epochs: 29000 reg_loss: 0.7094285588124348 loss: 0.6577864828877882\n",
      "epochs: 30000 reg_loss: 0.7094121103694849 loss: 0.6577484949645427\n",
      "epochs: 31000 reg_loss: 0.7093925084835767 loss: 0.6577243045997273\n",
      "epochs: 32000 reg_loss: 0.7093812541975826 loss: 0.6577002906101073\n",
      "epochs: 33000 reg_loss: 0.7093789950784957 loss: 0.6576964543190844\n",
      "epochs: 34000 reg_loss: 0.7093783617111762 loss: 0.6576983495607818\n",
      "epochs: 35000 reg_loss: 0.7093625544037809 loss: 0.6576665631005167\n",
      "epochs: 36000 reg_loss: 0.7093552027110136 loss: 0.657658689942391\n",
      "epochs: 37000 reg_loss: 0.709325396197882 loss: 0.6576228280724901\n",
      "epochs: 38000 reg_loss: 0.7092990959100419 loss: 0.657573701918217\n",
      "epochs: 39000 reg_loss: 0.7092930983654637 loss: 0.6575560016592622\n",
      "epochs: 40000 reg_loss: 0.7092799375165045 loss: 0.6575334807203939\n",
      "epochs: 41000 reg_loss: 0.7092804419613842 loss: 0.657535799601171\n",
      "epochs: 42000 reg_loss: 0.7092839397552422 loss: 0.6575383990298368\n",
      "epochs: 43000 reg_loss: 0.7092904977203001 loss: 0.6575518802727196\n",
      "epochs: 44000 reg_loss: 0.70925677645946 loss: 0.657500318009598\n",
      "epochs: 45000 reg_loss: 0.7092546113810133 loss: 0.6574880237787027\n",
      "epochs: 46000 reg_loss: 0.7092629001485579 loss: 0.6574996581268322\n",
      "epochs: 47000 reg_loss: 0.7092455415372301 loss: 0.6574612330201859\n",
      "epochs: 48000 reg_loss: 0.709202517747135 loss: 0.6574123286905001\n",
      "epochs: 49000 reg_loss: 0.709194415624315 loss: 0.6573867812170783\n",
      "epochs: 50000 reg_loss: 0.7091642937677405 loss: 0.6573334481533786\n",
      "CPU times: user 26min 41s, sys: 21.7 s, total: 27min 3s\n",
      "Wall time: 1h 1min 46s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7440090591742956"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model1.fit(batch_size=10000,learning_rate=0.0001 ,epochs=50000,n_show=1000)\n",
    "model1.loss(x_validation,y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K=10 lambda=0.1   validation=0.7440090591742956 model1 \n",
    "#K=20 lambda=0.1  validation=0.7437028511035796 model2\n",
    "#These two have been saved in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import regularizers\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "from keras.layers import Dot,Add,Input\n",
    "from keras.models import Model\n",
    "class keras_recommendation_model:\n",
    "    def __init__(self , x_train , y_train , K=5, r_lambda=0):\n",
    "        self.users=x_train[0].values\n",
    "        self.movies=x_train[1].values\n",
    "        self.y=y_train.values\n",
    "        self.users_input=Input(shape=[1,],name='users')\n",
    "        self.movies_input=Input(shape=[1,],name='movies')\n",
    "        self.users_embedding=Embedding(7000,K,input_length=1\n",
    "                                ,embeddings_initializer=keras.initializers.RandomNormal(stddev=1/np.sqrt(K))\n",
    "                                ,embeddings_regularizer=keras.regularizers.l2(r_lambda),name='users_embedding')(self.users_input)\n",
    "        self.movies_embedding=Embedding(10000,K,input_length=1\n",
    "                                ,embeddings_initializer=keras.initializers.RandomNormal(stddev=1/np.sqrt(K))\n",
    "                                ,embeddings_regularizer=keras.regularizers.l2(r_lambda),name='movies_embedding')(self.movies_input)\n",
    "        self.users_bias=Embedding(7000,1,input_length=1\n",
    "                                ,embeddings_initializer=keras.initializers.RandomNormal(stddev=0.0001)\n",
    "                                 ,name='users_bias')(self.users_input)\n",
    "        self.movies_bias=Embedding(10000,1,input_length=1,\n",
    "                                 embeddings_initializer=keras.initializers.RandomNormal(stddev=0.0001)\n",
    "                                  ,name='movies_bias')(self.movies_input)\n",
    "        self.interaction=Dot(axes=-1,name=\"interaction\")([self.users_embedding,self.movies_embedding])\n",
    "        self.out=Add(name='y_')([self.users_bias,self.movies_bias,self.interaction])\n",
    "        self.out_f=keras.layers.Flatten(name=\"output\")(self.out)\n",
    "        self.model=Model(inputs=[self.users_input,self.movies_input], outputs=self.out_f)\n",
    "        self.model.compile(optimizer=\"sgd\"\n",
    "                           ,loss=\"mean_squared_error\",metrics=['accuracy'])\n",
    "        self.model.summary()\n",
    "        keras.utils.plot_model(self.model,\"cf_model.png\",show_shapes=True)\n",
    "    def fit(self,each_epochs=100,batch_size_=100,turns=10,lr=0.001):\n",
    "        for i in range(turns):\n",
    "            keras.backend.set_value(self.model.optimizer.lr,lr)\n",
    "            result=self.model.fit([self.users,self.movies],self.y,epochs=each_epochs,\n",
    "                                  batch_size=batch_size_,verbose=1)\n",
    "            print(i*each_epochs,\"epochs finished. Loss:\",result.history)\n",
    "    def predict(self,x):\n",
    "        users=x[0].values\n",
    "        movies=x[1].values\n",
    "        return self.model.predict([users,movies])\n",
    "    \n",
    "                                                                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection, training and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "users (InputLayer)              (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "movies (InputLayer)             (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "users_embedding (Embedding)     (None, 1, 20)        140000      users[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "movies_embedding (Embedding)    (None, 1, 20)        200000      movies[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "users_bias (Embedding)          (None, 1, 1)         7000        users[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "movies_bias (Embedding)         (None, 1, 1)         10000       movies[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "interaction (Dot)               (None, 1, 1)         0           users_embedding[0][0]            \n",
      "                                                                 movies_embedding[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "y_ (Add)                        (None, 1, 1)         0           users_bias[0][0]                 \n",
      "                                                                 movies_bias[0][0]                \n",
      "                                                                 interaction[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "output (Flatten)                (None, 1)            0           y_[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 357,000\n",
      "Trainable params: 357,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model5=keras_recommendation_model(x_train,y_train,20,r_lambda=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8056 - acc: 0.4292\n",
      "Epoch 2/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8055 - acc: 0.4292\n",
      "Epoch 3/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8054 - acc: 0.4293\n",
      "Epoch 4/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8054 - acc: 0.4292\n",
      "Epoch 5/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8053 - acc: 0.4293\n",
      "Epoch 6/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8053 - acc: 0.4293\n",
      "Epoch 7/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8053 - acc: 0.4294\n",
      "Epoch 8/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8053 - acc: 0.4293\n",
      "Epoch 9/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 10/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "0 epochs finished. Loss: {'loss': [0.8055700976617799, 0.8054698478723009, 0.8054033051177671, 0.8053565500006828, 0.8053204560638829, 0.8052932437484078, 0.8052721892346877, 0.8052550672633081, 0.8052412018354183, 0.8052298886841579], 'acc': [0.42919040632110983, 0.42921165187362104, 0.4292741393654636, 0.4292341475190779, 0.4292991333300115, 0.42927413889710614, 0.42936661948121757, 0.42928913572274663, 0.429395363911871, 0.4293678691113925]}\n",
      "Epoch 1/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 2/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 3/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4294A: 0s - loss: 0.8048 - acc:\n",
      "Epoch 4/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4295\n",
      "Epoch 5/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 6/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4293\n",
      "Epoch 7/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 8/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 9/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 10/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "10 epochs finished. Loss: {'loss': [0.8052200740774403, 0.8052114181711264, 0.8052054449472874, 0.8051985870914687, 0.8051936139484818, 0.8051887892395466, 0.8051840074147263, 0.805179826160147, 0.8051769409832854, 0.8051739596757053], 'acc': [0.4293591216014682, 0.42938286585073604, 0.42935412251132765, 0.4294678484735313, 0.42939036517935814, 0.42934662344748115, 0.42939411419692614, 0.4294241078500694, 0.42940411200877854, 0.4294478526720183]}\n",
      "Epoch 1/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 2/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4295\n",
      "Epoch 3/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 4/10\n",
      "800167/800167 [==============================] - 2s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 5/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8052 - acc: 0.4295\n",
      "Epoch 6/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8052 - acc: 0.4295\n",
      "Epoch 7/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 8/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8052 - acc: 0.4295\n",
      "Epoch 9/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8052 - acc: 0.4294\n",
      "Epoch 10/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8052 - acc: 0.4295\n",
      "20 epochs finished. Loss: {'loss': [0.8051705678886004, 0.8051683451705702, 0.8051657935375365, 0.8051627237768743, 0.8051604610968329, 0.8051578835566096, 0.8051558354295866, 0.8051544872815413, 0.8051517754686087, 0.8051506774726241], 'acc': [0.42940536119454464, 0.42949159351895105, 0.42935162296568, 0.42943785462675066, 0.42946284905038207, 0.4294528510404973, 0.42941910888313567, 0.4294765966542032, 0.4294491021339943, 0.42946909894146096]}\n",
      "Epoch 1/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 2/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 3/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 4/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 5/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 6/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 7/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 8/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 9/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 10/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4294\n",
      "30 epochs finished. Loss: {'loss': [0.8051489208301449, 0.8051468157385608, 0.8051460100539618, 0.8051434890740409, 0.8051425559935986, 0.8051408619901248, 0.8051397888014067, 0.8051380469153727, 0.8051364391556745, 0.8051359412504371], 'acc': [0.4295328350448615, 0.4294690985767567, 0.42940286244467646, 0.4294503525997264, 0.4294591002434725, 0.4293891145252029, 0.4294765973814143, 0.42948159621705895, 0.4295453322522264, 0.4294391048221577]}\n",
      "Epoch 1/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 2/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 3/10\n",
      "800167/800167 [==============================] - 4s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 4/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 5/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 6/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 7/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 8/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 9/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 10/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4294\n",
      "40 epochs finished. Loss: {'loss': [0.8051340969911778, 0.8051320940253623, 0.8051313519809177, 0.8051304152373426, 0.8051290508356723, 0.8051275521466928, 0.8051264768061003, 0.8051249826896307, 0.8051242219959545, 0.8051238209968047], 'acc': [0.4294690982765982, 0.4294990924958301, 0.4295003417818601, 0.42950534045202465, 0.4294815953969957, 0.42950284160003027, 0.42952533614061045, 0.4295078401215495, 0.42947784644397347, 0.4294178588801742]}\n",
      "Epoch 1/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 2/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 3/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 4/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 5/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 6/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 7/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 8/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4296\n",
      "Epoch 10/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "50 epochs finished. Loss: {'loss': [0.8051224408446912, 0.8051209156182599, 0.8051195196692958, 0.8051187776206052, 0.8051174355987876, 0.8051169899748344, 0.8051154921939656, 0.8051148519917053, 0.8051131052206002, 0.8051121555181043], 'acc': [0.4294578503739976, 0.4294815960677432, 0.42943910485940284, 0.42943285569587025, 0.42944410304605113, 0.42943910433022403, 0.42950909020708344, 0.4294266067172225, 0.4295528308740104, 0.4294715969818095]}\n",
      "Epoch 1/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 2/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 3/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4296\n",
      "Epoch 4/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 5/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 6/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 7/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 8/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 9/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 10/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "60 epochs finished. Loss: {'loss': [0.8051111004141306, 0.8051102488564206, 0.805108739931735, 0.8051082163439707, 0.805108072573009, 0.8051058724817666, 0.8051056117091084, 0.80510371363049, 0.8051031819788576, 0.8051019606238057], 'acc': [0.4295328350197583, 0.4294815954050779, 0.4295628283820171, 0.42952408668723807, 0.4294665986933702, 0.4295365845789822, 0.4295003417520267, 0.4295290857662424, 0.4294865940929339, 0.42949909179997936]}\n",
      "Epoch 1/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 2/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 3/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4296\n",
      "Epoch 4/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 5/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 6/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 7/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 8/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 9/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 10/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "70 epochs finished. Loss: {'loss': [0.8051008903547333, 0.805100227534475, 0.8050993804787326, 0.8050982368211894, 0.8050970030210505, 0.8050963501424854, 0.8050948397359651, 0.8050939823194474, 0.8050932504097001, 0.8050921327035937], 'acc': [0.4294378549818457, 0.42953908290954473, 0.42955408105645615, 0.4295265863378797, 0.4295340852822438, 0.4295353345489063, 0.4294915938069676, 0.4294853451815526, 0.4294353549100362, 0.42952533647801405]}\n",
      "Epoch 1/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 2/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 3/10\n",
      "800167/800167 [==============================] - 4s 5us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 4/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 5/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 6/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 7/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 8/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 9/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 10/10\n",
      "800167/800167 [==============================] - 4s 5us/step - loss: 0.8051 - acc: 0.4296\n",
      "80 epochs finished. Loss: {'loss': [0.8050911778575456, 0.8050904461309698, 0.8050891505728218, 0.8050884285431641, 0.8050879260726425, 0.8050862999904269, 0.8050855861552187, 0.8050843220754612, 0.8050837129833859, 0.8050826606380844], 'acc': [0.42952158693648157, 0.4295053396798214, 0.42953658496104274, 0.42953158531442265, 0.4295003414569336, 0.42948409529218884, 0.4294753470720744, 0.4295253366247971, 0.4294603503938874, 0.4295515807733178]}\n",
      "Epoch 1/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 2/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4296\n",
      "Epoch 3/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 4/10\n",
      "800167/800167 [==============================] - 3s 4us/step - loss: 0.8051 - acc: 0.4296\n",
      "Epoch 5/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "Epoch 6/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 7/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 8/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 9/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4294\n",
      "Epoch 10/10\n",
      "800167/800167 [==============================] - 3s 3us/step - loss: 0.8051 - acc: 0.4295\n",
      "90 epochs finished. Loss: {'loss': [0.8050818542023256, 0.8050807876195525, 0.805079762270935, 0.8050791123065777, 0.8050782487177229, 0.8050771340146913, 0.805076401622992, 0.8050754265633424, 0.8050750066574481, 0.8050737251693177], 'acc': [0.4294528523809867, 0.4295553302009174, 0.42948909409986236, 0.4295565798767549, 0.42954158363928946, 0.4294403541944847, 0.42943785508330146, 0.42944535329051, 0.4294416033017008, 0.4294903440271417]}\n",
      "CPU times: user 8min 54s, sys: 51.3 s, total: 9min 46s\n",
      "Wall time: 4min 40s\n"
     ]
    }
   ],
   "source": [
    "%time model5.fit(10,1000,10,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8283043232710366"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_validation,model5.predict(x_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to limited time my Keras model doesn't have enough time to train so the result is not as good as the \"brute-force\" model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
